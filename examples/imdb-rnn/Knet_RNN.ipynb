{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knet RNN example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RNN (GRU) on IMDB - Natural Language Processing (Sentiment Analysis)\n",
    "\n",
    "#### Comparison with other frameworks from https://github.com/ilkarman/DeepLearningFrameworks\n",
    "\n",
    "| DL Library                          | Test Accuracy (%) | Training Time (s) | Using CuDNN? |\n",
    "| ----------------------------------- | ----------------- | ----------------- | ------------ |\n",
    "| [MXNet](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/MXNet_RNN.ipynb)            | 86                | 29                | Yes          |\n",
    "| [Knet(Julia)](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/Knet_RNN.ipynb)       | 85                | 29                | Yes          |\n",
    "| [Tensorflow](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/Tensorflow_RNN.ipynb)  | 86                | 30                | Yes          |\n",
    "| [Pytorch](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/PyTorch_RNN.ipynb)        | 86                | 31                | Yes          |\n",
    "| [CNTK](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/CNTK_RNN.ipynb)              | 85                | 32                | Yes          |\n",
    "| [Keras(TF)](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/Keras_TF_RNN.ipynb)     | 86                | 35                | Yes          |\n",
    "| [Keras(CNTK)](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/Keras_CNTK_RNN.ipynb) | 86                | 86                | No Available |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### After installing and starting Julia run the following to install the required packages:\n",
    "```\n",
    "julia> Pkg.init(); for p in (\"CUDAdrv\",\"IJulia\",\"Knet\",\"PyCall\",\"JLD2\"); Pkg.add(p); end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet\n",
    "EPOCHS=3\n",
    "BATCHSIZE=64\n",
    "EMBEDSIZE=125\n",
    "NUMHIDDEN=100\n",
    "DROPOUT=0.2\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "MAXLEN=150 #maximum size of the word sequence                                                                              \n",
    "MAXFEATURES=30000; #vocabulary size                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux\n",
      "Julia: 0.6.1\n",
      "Knet: 0.8.5+\n",
      "GPU: Tesla K80\n",
      "Tesla K80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"OS: \", Sys.KERNEL)\n",
    "println(\"Julia: \", VERSION)\n",
    "println(\"Knet: \", Pkg.installed(\"Knet\"))\n",
    "println(\"GPU: \", readstring(`nvidia-smi --query-gpu=name --format=csv,noheader`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "function initmodel()\n",
    "    rnnSpec,rnnWeights = rnninit(EMBEDSIZE,NUMHIDDEN; rnnType=:gru)\n",
    "    inputMatrix = KnetArray(xavier(Float32,EMBEDSIZE,MAXFEATURES))\n",
    "    outputMatrix = KnetArray(xavier(Float32,2,NUMHIDDEN))\n",
    "    return rnnSpec,(rnnWeights,inputMatrix,outputMatrix)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and its gradient\n",
    "function predict(weights, inputs, rnnSpec)\n",
    "    rnnWeights, inputMatrix, outputMatrix = weights # (1,1,W), (X,V), (2,H)\n",
    "    indices = hcat(inputs...)' # (B,T)\n",
    "    rnnInput = inputMatrix[:,indices] # (X,B,T)\n",
    "    rnnOutput = rnnforw(rnnSpec, rnnWeights, rnnInput)[1] # (H,B,T)\n",
    "    return outputMatrix * rnnOutput[:,:,end] # (2,H) * (H,B) = (2,B)\n",
    "end\n",
    "\n",
    "loss(w,x,y,r)=nll(predict(w,x,r),y)\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mLoading IMDB...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.007620 seconds (15.77 M allocations: 826.516 MiB, 3.70% gc time)\n",
      "25000-element Array{Array{Int32,1},1}\n",
      "25000-element Array{Int8,1}\n",
      "25000-element Array{Array{Int32,1},1}\n",
      "25000-element Array{Int8,1}\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "include(Knet.dir(\"data\",\"imdb.jl\"))\n",
    "@time (xtrn,ytrn,xtst,ytst,imdbdict)=imdb(maxlen=MAXLEN,maxval=MAXFEATURES)\n",
    "for d in (xtrn,ytrn,xtst,ytst); println(summary(d)); end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, \"this\", \"movie\", \"more\", \"that\", \"the\", \"ones\", \"who\", \"couldn't\", \"c'mon\", \"spastic\")\n",
      "(2, \"and\", \"shows\", \"about\", \"stupid\", \"doctors\", \"this\", \"is\", \"the\", \"deal\", \"oz\")\n",
      "(1, \"dropped\", \"about\", \"30\", \"points\", \"from\", \"watching\", \"this\", \"insert\", \"expletive\", \"here\")\n",
      "(2, \"a\", \"highly\", \"entertaining\", \"and\", \"suspenseful\", \"way\", \"it\", \"says\", \"it\", \"brilliantly\")\n",
      "(2, \"old\", \"generations\", \"my\", \"vote\", \"is\", \"nine\", \"br\", \"br\", \"title\", \"brazil\")\n",
      "(2, \"be\", \"no\", \"question\", \"that\", \"alan\", \"rickman\", \"is\", \"a\", \"major\", \"star\")\n",
      "(1, \"i\", \"have\", \"seen\", \"worse\", \"from\", \"big\", \"studios\", \"with\", \"vast\", \"budgets\")\n",
      "(1, \"beyond\", \"to\", \"mean\", \"anything\", \"really\", \"bad\", \"a\", \"spastic\", \"for\", \"boorman\")\n",
      "(1, \"the\", \"end\", \"br\", \"br\", \"i'm\", \"off\", \"to\", \"have\", \"a\", \"salad\")\n",
      "(2, \"without\", \"reservation\", \"as\", \"one\", \"of\", \"the\", \"finest\", \"films\", \"ever\", \"made\")\n"
     ]
    }
   ],
   "source": [
    "# Look at some sample data\n",
    "vocab = Array{String}(length(imdbdict))\n",
    "for (k,v) in imdbdict; vocab[v]=k; end\n",
    "for i in randperm(25000)[1:10]\n",
    "    println((ytst[i],vocab[xtst[i][end-9:end]]...))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "weights = nothing; knetgc(); # Reclaim memory from previous run\n",
    "rnnSpec,weights = initmodel()\n",
    "optim = optimizers(weights, Adam; lr=LR, beta1=BETA_1, beta2=BETA_2, eps=EPS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompile...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.176993 seconds (1.50 M allocations: 80.635 MiB, 0.76% gc time)\n"
     ]
    }
   ],
   "source": [
    "# force precompile (optional)\n",
    "info(\"Precompile...\")\n",
    "(x,y) = first(minibatch(xtrn,ytrn,BATCHSIZE))\n",
    "@time lossgradient(weights,x,y,rnnSpec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mTraining...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.149041 seconds (673.79 k allocations: 61.959 MiB, 4.16% gc time)\n",
      "  9.033643 seconds (353.06 k allocations: 44.302 MiB, 4.46% gc time)\n",
      "  9.141217 seconds (361.52 k allocations: 44.431 MiB, 5.48% gc time)\n",
      " 28.325220 seconds (1.39 M allocations: 150.928 MiB, 4.68% gc time)\n"
     ]
    }
   ],
   "source": [
    "info(\"Training...\")\n",
    "@time for epoch in 1:EPOCHS\n",
    "    @time for (x,y) in minibatch(xtrn,ytrn,BATCHSIZE;shuffle=true)\n",
    "        grads = lossgradient(weights,x,y,rnnSpec)\n",
    "        update!(weights, grads, optim)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mTesting...\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.300192 seconds (663.92 k allocations: 66.624 MiB, 3.60% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.853125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info(\"Testing...\")\n",
    "@time accuracy(weights, minibatch(xtst,ytst,BATCHSIZE), (w,x)->predict(w,x,rnnSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
