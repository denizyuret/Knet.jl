{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Plots, JLD, NBInclude\n",
    "nbinclude(\"mnist.ipynb\")  # loads MNIST, defines dtrn,dtst,Atype,train,softmax,zeroone\n",
    "ENV[\"COLUMNS\"]=80         # column width for array printing\n",
    "plotlyjs();               # for interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predict function returns a score for each class as a linear function of input x\n",
    "function linear(w,x)\n",
    "    y = w[1]*mat(x) .+ w[2]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights as a list of [ weightMatrix, biasVector ]\n",
    "winit1(;std=0.01)=map(Atype, [ std*randn(10,784), zeros(10,1) ]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and zero-one loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"28×28×1×100 Knet.KnetArray{Float32,4}\", \"100-element Array{UInt8,1}\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a minibatch\n",
    "x,y = first(dtst)\n",
    "map(summary,(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×100 Array{Float32,2}:\n",
       "  0.020949      0.0204775   -0.0932485   …  -0.0769949   -0.0152675\n",
       "  0.0455851    -0.0707735   -0.0228169       0.00569148   0.0522016\n",
       " -0.000504205  -0.214745     0.00253635     -0.082528    -0.107451 \n",
       "  0.132813     -0.103564     0.0237599       0.0487591   -0.0231088\n",
       "  0.0351397    -0.0638922   -0.109847       -0.0460735   -0.100915 \n",
       " -0.0180563    -0.0725433   -0.08814     …   0.00757484  -0.13144  \n",
       "  0.0370442     0.00319698  -0.0865752       0.079252     0.0637138\n",
       " -0.010542      0.0478139    0.0305943       0.107525     0.138668 \n",
       " -0.0714492    -0.124502    -0.00765008     -0.00235417   0.026818 \n",
       "  0.173877      0.296371     0.0476608       0.148999     0.268136 "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize random model and calculate predictions for one minibatch\n",
    "setseed(9)           # for replicability\n",
    "w = winit1()         # random weight matrix and a zero bias vector\n",
    "ypred = linear(w,x)  # predict\n",
    "Array(ypred)         # predictions are given as a 10xN score matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×100 RowVector{UInt8,Array{UInt8,1}}:\n",
       " 0x07  0x02  0x01  0x0a  0x04  0x01  …  0x01  0x04  0x01  0x07  0x06  0x09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y'  # correct answers are given as an array of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy gives percentage of correct answers\n",
    "accuracy(ypred,y)        # 2-arg version: accuracy on this batch of 100 with initial w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0971"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(w,dtst,linear)  # 3-arg version: accuracy on the whole test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zeroone loss (error) defined as 1 - accuracy\n",
    "zeroone(w,data,model) = 1 - accuracy(w,data,model)\n",
    "zeroone(w,dtst,linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 2 methods)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate softmax (cross entropy, negative log likelihood) loss of a model with weights w for one minibatch (x,y)\n",
    "# Predict specifies the function for model output: ypred = predict(w,x;o...)\n",
    "softmax(w,x,y,predict; o...)=nll(predict(w,x;o...),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.30209f0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-instance average softloss for the first test minibatch, should be close to -log(1/10)=2.3\n",
    "softmax(w,x,y,linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.30209f0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual loss calculation\n",
    "ypred=linear(w,x)\n",
    "yp1 = exp.(ypred)\n",
    "yp2 = yp1 ./ sum(yp1,1)\n",
    "yp3 = -log.(yp2)\n",
    "yc1 = full(sparse(y,1:100,1f0))\n",
    "sum(Array(yp3).*yc1) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2936275f0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(w,data,predict) = mean(softmax(w,x,y,predict) for (x,y) in data)\n",
    "softmax(w,dtst,linear)  # per-instance average softmax loss for the whole test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the gradient using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::gradfun) (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically defined gradient for softloss\n",
    "softgrad = grad(softmax)  # softgrad returns gradient wrt 1st arg w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Knet.KnetArray{Float32,2},1}:\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x000000810702d800, 31360, 0, nothing), (10, 784))\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x0000008105400800, 40, 0, nothing), (10, 1))     "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setseed(9)\n",
    "w1 = winit1(std=0.1)  # use a larger std to get a larger gradient for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x0000008107035400, 31360, 0, nothing), (10, 784))\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x0000008105400a00, 40, 0, nothing), (10, 1))     "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = softgrad(w1,x,y,linear)  # gradient has the same size and shape as the first parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the gradient using numerical approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 Array{Float32,2}:\n",
       " -0.0921663  -0.00683322  -0.0612594  …  0.0736465  -0.0507283  0.345075"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array(g1[2])'  \n",
    "# Meaning of gradient:\n",
    "# If I move the last entry of w[2] by epsilon, loss will go up by 0.345075 epsilon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 Array{Float32,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array(w1[2])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8222036f0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(w1,x,y,linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×10 Array{Float32,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1[2][10] = 0.1   # to numerically check the gradient let's move the last entry by +0.1.\n",
    "Array(w1[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8577392f0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(w1,x,y,linear)  \n",
    "# We see that the loss moves by +0.03 as expected.\n",
    "# You should check all/most entries in your gradients this way to make sure they are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the gradient using manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually defined gradient for softloss\n",
    "function softgrad_manual(w,x,y,predict)\n",
    "    x = mat(x)\n",
    "    p = predict(w,x)\n",
    "    p = p .- maximum(p,1) # for numerical stability\n",
    "    expp = exp.(p)\n",
    "    p = expp ./ sum(expp,1)\n",
    "    q = oftype(p, sparse(convert(Vector{Int},y),1:length(y),1,size(p,1),length(y)))\n",
    "    dJdy = (p - q) / size(x,2)\n",
    "    dJdw = dJdy * x'\n",
    "    dJdb = sum(dJdy,2)\n",
    "    Any[dJdw,dJdb]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Any,1}:\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x000000810703d000, 31360, 0, nothing), (10, 784))\n",
       " Knet.KnetArray{Float32,2}(Knet.KnetPtr(Ptr{Nothing} @0x0000008105400e00, 40, 0, nothing), (10, 1))     "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2 = softgrad_manual(w1,x,y,linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1[1] ≈ g2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1[2] ≈ g2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (SGD) loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model(w) with SGD and return a list containing w for every epoch\n",
    "function train(w,data,predict; epochs=100,lr=0.1,o...)\n",
    "    weights = Any[deepcopy(w)]\n",
    "    for epoch in 1:epochs\n",
    "        for (x,y) in data\n",
    "            g = softgrad(w,x,y,predict;o...)\n",
    "            update!(w,g,lr=lr)  # w[i] = w[i] - lr * g[i]\n",
    "        end\n",
    "        push!(weights,deepcopy(w))\n",
    "    end\n",
    "    return weights\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the linear model and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26674008f0, 0.07440000000000002)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if !isfile(\"lin.jld\")\n",
    "    setseed(1)\n",
    "    @time weights = train(winit1(),dtrn,linear,lr=0.1)           # 31.1s\n",
    "    @time trnloss = [ softmax(w,dtrn,linear) for w in weights ]  # 22.2s\n",
    "    @time tstloss = [ softmax(w,dtst,linear) for w in weights ]  # 3.7s\n",
    "    @time trnerr  = [ zeroone(w,dtrn,linear) for w in weights ]  # 20.6s\n",
    "    @time tsterr  = [ zeroone(w,dtst,linear) for w in weights ]  # 3.4s\n",
    "    @save \"lin.jld\" weights trnloss tstloss trnerr tsterr\n",
    "else\n",
    "    @eval (@load \"lin.jld\")\n",
    "end\n",
    "minimum(tstloss),minimum(tsterr)  # 0.2667, 0.0744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([trnloss tstloss],ylim=(.2,.36),labels=[:trnloss :tstloss],xlabel=\"Epochs\",ylabel=\"Loss\") \n",
    "# Demonstrates underfitting: training loss not close to 0\n",
    "# Also slight overfitting: test loss higher than train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([trnerr tsterr],ylim=(.06,.10),labels=[:trnerr :tsterr],xlabel=\"Epochs\",ylabel=\"Error\")  \n",
    "# this is the error plot, we get to about 7.5% test error, i.e. 92.5% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×280 Array{Gray{Float64},2}:\n",
       " Gray{Float64}(0.502973)  Gray{Float64}(0.505837)  …  Gray{Float64}(0.510452)\n",
       " Gray{Float64}(0.498021)  Gray{Float64}(0.498761)     Gray{Float64}(0.487111)\n",
       " Gray{Float64}(0.499189)  Gray{Float64}(0.500012)     Gray{Float64}(0.507376)\n",
       " Gray{Float64}(0.504791)  Gray{Float64}(0.501311)     Gray{Float64}(0.502395)\n",
       " Gray{Float64}(0.502787)  Gray{Float64}(0.515505)     Gray{Float64}(0.49603) \n",
       " Gray{Float64}(0.510182)  Gray{Float64}(0.479837)  …  Gray{Float64}(0.48333) \n",
       " Gray{Float64}(0.501108)  Gray{Float64}(0.501805)     Gray{Float64}(0.448243)\n",
       " Gray{Float64}(0.506617)  Gray{Float64}(0.491905)     Gray{Float64}(0.491801)\n",
       " Gray{Float64}(0.530667)  Gray{Float64}(0.482081)     Gray{Float64}(0.495283)\n",
       " Gray{Float64}(0.486299)  Gray{Float64}(0.49181)      Gray{Float64}(0.495922)\n",
       " Gray{Float64}(0.496492)  Gray{Float64}(0.498168)  …  Gray{Float64}(0.486094)\n",
       " Gray{Float64}(0.484261)  Gray{Float64}(0.496982)     Gray{Float64}(0.51029) \n",
       " Gray{Float64}(0.514808)  Gray{Float64}(0.516375)     Gray{Float64}(0.493388)\n",
       " ⋮                                                 ⋱                         \n",
       " Gray{Float64}(0.500184)  Gray{Float64}(0.500895)     Gray{Float64}(0.502697)\n",
       " Gray{Float64}(0.509027)  Gray{Float64}(0.501976)     Gray{Float64}(0.536902)\n",
       " Gray{Float64}(0.509976)  Gray{Float64}(0.486919)     Gray{Float64}(0.49857) \n",
       " Gray{Float64}(0.479531)  Gray{Float64}(0.486981)     Gray{Float64}(0.50483) \n",
       " Gray{Float64}(0.507166)  Gray{Float64}(0.493379)  …  Gray{Float64}(0.499078)\n",
       " Gray{Float64}(0.513485)  Gray{Float64}(0.504389)     Gray{Float64}(0.497865)\n",
       " Gray{Float64}(0.483163)  Gray{Float64}(0.491273)     Gray{Float64}(0.495207)\n",
       " Gray{Float64}(0.502502)  Gray{Float64}(0.511835)     Gray{Float64}(0.47999) \n",
       " Gray{Float64}(0.492932)  Gray{Float64}(0.512126)     Gray{Float64}(0.486339)\n",
       " Gray{Float64}(0.499899)  Gray{Float64}(0.488099)  …  Gray{Float64}(0.511448)\n",
       " Gray{Float64}(0.502088)  Gray{Float64}(0.50586)      Gray{Float64}(0.488382)\n",
       " Gray{Float64}(0.499835)  Gray{Float64}(0.528453)     Gray{Float64}(0.500367)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Epoch 100\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in logspace(0,2,20)\n",
    "    i = ceil(Int,t)\n",
    "    w = weights[i]\n",
    "    w1 = reshape(Array(w[1])', (28,28,1,10))\n",
    "    w2 = clamp.(w1.+0.5,0,1)\n",
    "    IJulia.clear_output(true)\n",
    "    display(hcat([mnistview(w2,i) for i=1:10]...))\n",
    "    display(\"Epoch $i\")\n",
    "    sleep(1) # (0.96^i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
