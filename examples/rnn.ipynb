{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A one layer MLP vs a simple RNN\n",
    "\n",
    "([Elman 1990](http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1/pdf)) A simple RNN takes the previous hidden state as an extra input, and returns the next hidden state as an extra output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png\" width=\"150\" />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mlp1(param, input)\n",
    "    hidden = tanh(input * param[1] .+ param[2])\n",
    "    output = hidden * param[3] .+ param[4]\n",
    "    return output\n",
    "end\n",
    "\n",
    "function rnn1(param, hidden, input)\n",
    "    input2 = hcat(hidden, input)\n",
    "    hidden = tanh(input2 * param[1] .+ param[2])\n",
    "    output = hidden * param[3] .+ param[4]\n",
    "    return (hidden, output)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through time (BPTT)\n",
    "\n",
    "([Werbos, 1988](http://www.sciencedirect.com/science/article/pii/089360808890007X))\n",
    "An RNN unrolled in time is similar to a deep feed-forward network which (i) has as many layers as time steps, (ii) has weights shared between different layers, and (iii) may have multiple inputs and outputs received and produced at individual layers. Backpropagation can be used to train RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=800 />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rnnloss(param,state,inputs,outputs)\n",
    "    # inputs and outputs are sequences of the same length\n",
    "    sumloss = 0\n",
    "    for t in 1:length(inputs)\n",
    "        prediction,state = rnn1(param,inputs[t],state)\n",
    "        sumloss += cross_entropy_loss(prediction,outputs[t])\n",
    "    end\n",
    "    return sumloss\n",
    "end\n",
    "\n",
    "rnngrad = grad(rnnloss)\n",
    "\n",
    "# train with our usual SGD procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory (LSTM)\n",
    "([Hochreiter and Schmidhuber, 1997](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf))\n",
    "LSTM is a more sophisticated RNN module that performs better with long-range dependencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=800 />\n",
    "([image source](http://colah.github.io/posts/2015-08-Understanding-LSTMs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "f_t &= \\sigma(W_f\\cdot[h_{t-1},x_t] + b_f) & \\text{forget gate} \\\\\n",
    "i_t &= \\sigma(W_i\\cdot[h_{t-1},x_t] + b_i) & \\text{input gate} \\\\\n",
    "\\tilde{C}_t &= \\tanh(W_C\\cdot[h_{t-1},x_t] + b_C) & \\text{cell candidate} \\\\\n",
    "C_t &= f_t \\ast C_{t-1} + i_t \\ast \\tilde{C}_t & \\text{new cell} \\\\\n",
    "o_t &= \\sigma(W_o\\cdot[h_{t-1},x_t] + b_o) & \\text{output gate} \\\\\n",
    "h_t &= o_t \\ast \\tanh(C_t) & \\text{new output}\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.google.com/drawings/d/1BR871g8k4jpI-mKeXiJfpY5Jl5cKcognvH7hHSugQds/pub?w=958&h=236\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lstm(param, state, input)\n",
    "    weight,bias = param\n",
    "    hidden,cell = state\n",
    "    h       = size(hidden,2)\n",
    "    gates   = hcat(input,hidden) * weight .+ bias\n",
    "    forget  = sigm.(gates[:,1:h])\n",
    "    ingate  = sigm.(gates[:,1+h:2h])\n",
    "    outgate = sigm.(gates[:,1+2h:3h])\n",
    "    change  = tanh.(gates[:,1+3h:4h])\n",
    "    cell    = cell .* forget + ingate .* change\n",
    "    hidden  = outgate .* tanh.(cell)\n",
    "    return (hidden,cell)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to sequence model (S2S)\n",
    "([Sutskever et al. 2014](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf))\n",
    "S2S models learn to map input sequences to output sequences using an encoder and a decoder RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nzw0301.github.io/images/seq2seq.svg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function initmodel(H, V; atype=(gpu()>=0 ? KnetArray{Float32} : Array{Float32}))\n",
    "    init(d...)=atype(xavier(d...))\n",
    "    model = Dict{Symbol,Any}()\n",
    "    model[:state0] = [ init(1,H), init(1,H) ]\n",
    "    model[:embed1] = init(V,H)\n",
    "    model[:encode] = [ init(2H,4H), init(1,4H) ]\n",
    "    model[:embed2] = init(V,H)\n",
    "    model[:decode] = [ init(2H,4H), init(1,4H) ]\n",
    "    model[:output] = [ init(H,V), init(1,V) ]\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function s2s(model, inputs, outputs)\n",
    "    state = initstate(inputs[1], model[:state0])\n",
    "    for input in reverse(inputs)\n",
    "        input = onehotrows(input, model[:embed1])\n",
    "        input = input * model[:embed1]\n",
    "        state = lstm(model[:encode], state, input)\n",
    "    end\n",
    "    EOS = eosmatrix(outputs[1], model[:embed2])\n",
    "    input = EOS * model[:embed2]\n",
    "    sumlogp = 0\n",
    "    for output in outputs\n",
    "        state = lstm(model[:decode], state, input)\n",
    "        ypred = predict(model[:output], state[1])\n",
    "        ygold = onehotrows(output, model[:embed2])\n",
    "        sumlogp += sum(ygold .* logp(ypred,2))\n",
    "        input = ygold * model[:embed2]\n",
    "    end\n",
    "    state = lstm(model[:decode], state, input)\n",
    "    ypred = predict(model[:output], state[1])\n",
    "    sumlogp += sum(EOS .* logp(ypred,2))\n",
    "    return -sumlogp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(param, input)\n",
    "    input * param[1] .+ param[2]\n",
    "end\n",
    "\n",
    "function initstate(idx, state0)\n",
    "    h,c = state0\n",
    "    h = h .+ fill!(similar(AutoGrad.getval(h), length(idx), length(h)), 0)\n",
    "    c = c .+ fill!(similar(AutoGrad.getval(c), length(idx), length(c)), 0)\n",
    "    return (h,c)\n",
    "end\n",
    "\n",
    "function onehotrows(idx, embeddings)\n",
    "    nrows,ncols = length(idx), size(embeddings,1)\n",
    "    z = zeros(Float32,nrows,ncols)\n",
    "    @inbounds for i=1:nrows\n",
    "        z[i,idx[i]] = 1\n",
    "    end\n",
    "    oftype(AutoGrad.getval(embeddings),z)\n",
    "end\n",
    "\n",
    "let EOS=nothing; global eosmatrix\n",
    "function eosmatrix(idx, embeddings)\n",
    "    nrows,ncols = length(idx), size(embeddings,1)\n",
    "    if EOS==nothing || size(EOS) != (nrows,ncols)\n",
    "        EOS = zeros(Float32,nrows,ncols)\n",
    "        EOS[:,1] = 1\n",
    "        EOS = oftype(AutoGrad.getval(embeddings), EOS)\n",
    "    end\n",
    "    return EOS\n",
    "end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function readdata(file=\"/usr/share/dict/words\")\n",
    "    global strings = map(chomp,readlines(file))\n",
    "    global tok2int = Dict{Char,Int}()\n",
    "    global int2tok = Vector{Char}()\n",
    "    push!(int2tok,'\\n'); tok2int['\\n']=1 # We use '\\n'=>1 as the EOS token                                                 \n",
    "    sequences = Vector{Vector{Int}}()\n",
    "    for w in strings\n",
    "        s = Vector{Int}()\n",
    "        for c in collect(w)\n",
    "            if !haskey(tok2int,c)\n",
    "                push!(int2tok,c)\n",
    "                tok2int[c] = length(int2tok)\n",
    "            end\n",
    "            push!(s, tok2int[c])\n",
    "        end\n",
    "        push!(sequences, s)\n",
    "    end\n",
    "    return sequences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = readdata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minibatch(sequences, batchsize)\n",
    "    table = Dict{Int,Vector{Vector{Int}}}()\n",
    "    data = Any[]\n",
    "    for s in sequences\n",
    "        n = length(s)\n",
    "        nsequences = get!(table, n, Any[])\n",
    "        push!(nsequences, s)\n",
    "        if length(nsequences) == batchsize\n",
    "            push!(data, [[ nsequences[i][j] for i in 1:batchsize] for j in 1:n ])\n",
    "            empty!(nsequences)\n",
    "        end\n",
    "    end\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize, statesize, vocabsize = 100, 128, length(int2tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = minibatch(sequences,batchsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initmodel(statesize,vocabsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function avgloss(model, data)\n",
    "    sumloss = cntloss = 0\n",
    "    for sequence in data\n",
    "        tokens = (1 + length(sequence)) * length(sequence[1])\n",
    "        sumloss += s2s(model, sequence, sequence)\n",
    "        cntloss += tokens\n",
    "    end\n",
    "    return sumloss/cntloss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgloss(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sgrad = grad(s2s)\n",
    "\n",
    "function train(model, data, opts)\n",
    "    for sequence in data\n",
    "        grads = s2sgrad(model, sequence, sequence)\n",
    "        update!(model, grads, opts)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = oparams(model,Adam);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(model,data,opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgloss(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch=1:10\n",
    "    train(model,data,opts)\n",
    "    println((epoch,avgloss(model,data)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function translate(model, str)\n",
    "    state = model[:state0]\n",
    "    for c in reverse(collect(str))\n",
    "        input = onehotrows(tok2int[c], model[:embed1])\n",
    "        input = input * model[:embed1]\n",
    "        state = lstm(model[:encode], state, input)\n",
    "    end\n",
    "    input = eosmatrix(1, model[:embed2]) * model[:embed2]\n",
    "    output = Char[]\n",
    "    for i=1:100 #while true                                                                                                \n",
    "        state = lstm(model[:decode], state, input)\n",
    "        pred = predict(model[:output], state[1])\n",
    "        i = indmax(Array(pred))\n",
    "        i == 1 && break\n",
    "        push!(output, int2tok[i])\n",
    "        input = onehotrows(i, model[:embed2]) * model[:embed2]\n",
    "    end\n",
    "    String(output)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(model,\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
