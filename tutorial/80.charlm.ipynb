{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Character based RNN language model\n",
    "(c) Deniz Yuret, 2019. Based on http://karpathy.github.io/2015/05/21/rnn-effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objectives: Learn to define and train a character based language model and generate text from it. Minibatch blocks of text. Keep a persistent RNN state between updates. Train a Shakespeare generator and a Julia programmer using the same type of model.\n",
    "* Prerequisites: [RNN basics](60.rnn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display width, load packages, import symbols\n",
    "ENV[\"COLUMNS\"]=72\n",
    "using Pkg; haskey(Pkg.installed(),\"Knet\") || Pkg.add(\"Knet\")\n",
    "using Knet: param, param0, RNN, dropout, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "Embed(vocab::Int,embed::Int)=Embed(param(embed,vocab))\n",
    "\n",
    "(e::Embed)(x) = e.w[:,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Linear; w; b; end\n",
    "\n",
    "Linear(input::Int, output::Int)=Linear(param(output,input), param0(output))\n",
    "\n",
    "(l::Linear)(x) = l.w * x .+ l.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the datasets used in this notebook, consecutive minibatches follow each other in time. Thus we want to start each iteration with the RNN hidden state from the previous iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct CharLM; input; rnn; output; hidden; end\n",
    "\n",
    "CharLM(vocab::Int,embed::Int,rnn::Int; o...) = \n",
    "    CharLM(Embed(vocab,embed), RNN(embed,rnn; o...), Linear(rnn,vocab), [])\n",
    "\n",
    "function (c::CharLM)(x)\n",
    "    x = c.input(x)                # (B,T)->(X,B,T)\n",
    "    x = c.rnn(x, hidden=c.hidden) # (H,B,T)\n",
    "    c.hidden .= value.(c.hidden)  # avoid deps in next iter\n",
    "    x = reshape(x, size(x,1), :)  # (H,B*T)\n",
    "    return c.output(x)            # (V,B*T)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# To generate text from trained models\n",
    "function generate(model,chars,n)\n",
    "    function sample(y)\n",
    "        p = Array(exp.(y)); r = rand()*sum(p)\n",
    "        for j=1:length(p); (r -= p[j]) < 0 && return j; end\n",
    "    end\n",
    "    x = 1\n",
    "    h = []\n",
    "    for i=1:n\n",
    "        y = model([x], hidden=h)\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running experiments\n",
    "using Knet: AutoGrad, Knet, train!, Adam; import ProgressMeter\n",
    "function trainresults1(file,model,chars)\n",
    "    if (print(\"Train from scratch? \");readline()[1]=='y')\n",
    "        updates = 0; prog = ProgressMeter.Progress(EPOCHS * length(dtrn))\n",
    "        callback(J)=(ProgressMeter.update!(prog, updates); (updates += 1) <= prog.n)\n",
    "        opt = Adam(lr=LR, beta1=BETA_1, beta2=BETA_2, eps=EPS)\n",
    "        train!(model, dtrn; callback=callback, optimizer=opt, pdrop=DROPOUT, hidden=[])\n",
    "        Knet.gc(); Knet.save(file,\"model\",model,\"chars\",chars)\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        model,chars = Knet.load(file,\"model\",\"chars\")\n",
    "    end\n",
    "    return model,chars\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running experiments\n",
    "function trainresults(file,model,chars)\n",
    "    if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "        progress!(adam(model,dtrn;lr=LR,beta1=BETA_1,beta2=BETA_2,eps=EPS))\n",
    "        Knet.save(file,\"model\",model,\"chars\",chars)\n",
    "        Knet.gc() # To save gpu memory\n",
    "    else\n",
    "        isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "        model,chars = Knet.load(file,\"model\",\"chars\")\n",
    "    end\n",
    "    return model,chars\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Complete Works of William Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "INPUTSIZE = 168\n",
    "VOCABSIZE = 84\n",
    "HIDDENSIZE = 334\n",
    "NUMLAYERS = 1\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "EPOCHS = 30\n",
    "ENV[\"COLUMNS\"]=92;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Load 'The Complete Works of William Shakespeare'\n",
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Print a sample\n",
    "println(string(chars[trn[1020:1210]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Minibatch data\n",
    "using Knet: minibatch\n",
    "function mb(a)\n",
    "    N = length(a) รท BATCHSIZE\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb.((trn,tst))\n",
    "length.((dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.(first(dtrn))  # each x and y have dimensions (BATCHSIZE,SEQLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakemodel,shakechars = trainresults(\"shakespeare113.jld2\", \n",
    "    CharLM(VOCABSIZE, INPUTSIZE, HIDDENSIZE; rnnType=RNNTYPE, numLayers=NUMLAYERS, dropout=DROPOUT), chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: nll\n",
    "exp(nll(shakemodel,dtst))  # Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "generate(shakemodel,shakechars,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia programmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNTYPE = :lstm\n",
    "BATCHSIZE = 64\n",
    "SEQLENGTH = 64\n",
    "INPUTSIZE = 512\n",
    "VOCABSIZE = 128\n",
    "HIDDENSIZE = 512\n",
    "NUMLAYERS = 2\n",
    "LR=0.001\n",
    "BETA_1=0.9\n",
    "BETA_2=0.999\n",
    "EPS=1e-08\n",
    "EPOCHS = 10\n",
    "ENV[\"COLUMNS\"]=92;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read julia base library source code\n",
    "base = joinpath(Sys.BINDIR, Base.DATAROOTDIR, \"julia\")\n",
    "text = \"\"\n",
    "for (root,dirs,files) in walkdir(base)\n",
    "    for f in files\n",
    "        f[end-2:end] == \".jl\" || continue\n",
    "        text *= read(joinpath(root,f), String)\n",
    "    end\n",
    "    # println((root,length(files),all(f->contains(f,\".jl\"),files)))\n",
    "end\n",
    "length(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique chars, sort by frequency, assign integer ids.\n",
    "charcnt = Dict{Char,Int}()\n",
    "for c in text; charcnt[c]=1+get(charcnt,c,0); end\n",
    "chars = sort(collect(keys(charcnt)), by=(x->charcnt[x]), rev=true)\n",
    "charid = Dict{Char,Int}()\n",
    "for i=1:length(chars); charid[chars[i]]=i; end\n",
    "hcat(chars, map(c->charcnt[c],chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only VOCABSIZE most frequent chars, split into train and test\n",
    "data = map(c->charid[c], collect(text))\n",
    "data[data .> VOCABSIZE] .= VOCABSIZE\n",
    "ntst = 1<<19\n",
    "tst = data[1:ntst]\n",
    "trn = data[1+ntst:end]\n",
    "length.((data,trn,tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample\n",
    "r = rand(1:(length(trn)-1000))\n",
    "println(string(chars[trn[r:r+1000]]...)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatch data\n",
    "using Knet: minibatch\n",
    "function mb(a)\n",
    "    N = length(a) รท BATCHSIZE\n",
    "    x = reshape(a[1:N*BATCHSIZE],N,BATCHSIZE)' # reshape full data to (B,N) with contiguous rows\n",
    "    minibatch(x[:,1:N-1], x[:,2:N], SEQLENGTH) # split into (B,T) blocks \n",
    "end\n",
    "dtrn,dtst = mb.((trn,tst))\n",
    "length.((dtrn,dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.(first(dtrn))  # each x and y have dimensions (BATCHSIZE,SEQLENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juliamodel,juliachars = trainresults(\"juliacharlm113.jld2\", \n",
    "    CharLM(VOCABSIZE, INPUTSIZE, HIDDENSIZE; rnnType=RNNTYPE, numLayers=NUMLAYERS, dropout=DROPOUT),chars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet: nll\n",
    "exp(nll(juliamodel,dtst))  # Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(juliamodel,juliachars,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "julia.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
