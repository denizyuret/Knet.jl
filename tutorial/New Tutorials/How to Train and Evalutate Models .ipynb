{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Models\n",
    "In this notebook, we will learn how to train a defined model and evalute its performance.\n",
    "* Objectives: Learning built-in training (adam, ada), evaluating (accuracy) functions\n",
    "* Prerequisites: Knet Neural Network Architecture and Layers notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Knet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"Knet\")\n",
    "using Knet\n",
    "using MLDatasets\n",
    "#You may see an error if your device does not support CUDA or your CUDA driver is not CUDA 10.1 or higher but you will be\n",
    "#able to use all the functionalities, except GPU operations, in spite of this error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remember our layer and model definitions from the last tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct dense; w; b; f; end\n",
    "(d::dense)(x) = d.f.(d.w * mat(x) .+ d.b)\n",
    "dense(i::Int,o::Int,f=relu) = dense(param(o,i), param0(o), f);\n",
    "\n",
    "struct Conv; w; b; f; end\n",
    "(c::Conv)(x) = c.f.(pool(conv4(c.w, x) .+ c.b))\n",
    "Conv(w1,w2,cx,cy,f=relu) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f);\n",
    "\n",
    "struct Chain; layers; Chain(args...)= new(args);end\n",
    "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "(c::Chain)(x,y) = nll(c(x),y)\n",
    "\n",
    "LeNet = Chain(Conv(5,5,1,20), Conv(5,5,20,50), dense(800,500), dense(500,10,identity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we need to train the model will be imported from an open source Julia library [MLDatasets](https://github.com/JuliaML/MLDatasets.jl). Details of importing data and using built-in Knet utilities for preprocessing will be explained in depth later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "xtrn,ytrn = MNIST.traindata(Float32); ytrn[ytrn.==0] .= 10\n",
    "xtst,ytst = MNIST.testdata(Float32);  ytst[ytst.==0] .= 10\n",
    "dtrn = minibatch(xtrn, ytrn, 100; xsize=(size(xtrn,1),size(xtrn,2),1,:))\n",
    "dtst = minibatch(xtst, ytst, 100; xsize=(size(xtst,1),size(xtst,2),1,:));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Knet, we pass the model and data to optimizer functions instead of conventional \"model.train\" way.\n",
    "Built-in optimization functions:\n",
    "* adam\n",
    "* adadelta\n",
    "* momentum\n",
    "* rmsprop\n",
    "* adagrad\n",
    "* nesterov\n",
    "\n",
    "An in-depth explanation of the optimization algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam(LeNet, ncycle(dtrn,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ncycle function is built in [IterTools](https://juliacollections.github.io/IterTools.jl/latest/) library that takes the data as the first parameter and the number of epochs as the second parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc nycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trained (it will take 30 seconds to 10 minutes depending on the CPU/GPU power), you will see that the function does not visualize the progress. For that, Knet has a function named progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress!(adam(LeNet, ncycle(dtrn,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knet also has the function \"train!\" which is deprecated but still fully functional:\n",
    "\n",
    "function train!(model, data; loss=nll, optimizer=Adam(), callback=epochs(data,1), o...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress!(train!(model, dtrn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
